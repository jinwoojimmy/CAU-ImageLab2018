# 28/05/18 Daily Report



## CNN Architecture

*CNN(Convolutional Neural Network)* is neural network utilized in image processing , MLP and so on.
The key idea is *convolution*, which means only small portion of image is handled at a time. This small portion is called 'patch',
and whole input image is processed by size of the patch.


### History

CNN was firstly introduced at 1989 by LeCun's paper ; "Backpropagation applied to handwritten zip code recognition."

The paper showed meaningful result, but it was not enough for commoditization.

At 2003, Simard's paper, "Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis" was published.

The paper simplified the model, and it had become cornerstone for broad use.

### Problems on pre-existing MLP

There were problems on pre-existing MLP.
    
    - Enormous number of free parameters 
    
    - Huge network size
    
    - Long time consumption for training

**CNN** was suggested to resolve the above problems.


### Idea of CNN

In human's neural network, there is part called receptive field, which occurs respond to information processing related cell. 

The characteristic of this receptive field is that, external stimulus affects not only on entire area, but on *certain specific area*.



Likewise, in image or media, pixels in certain area have high correlation with surrounding pixels, but the correlation decreases as distance between pixel increases. 

CNN has appeared based on this idea.



### Process of CNN

<img src="https://github.com/jwcse/DeepLearning/blob/master/img/cnn_overview.PNG" width="800" height="250">


### Overview of CNN
    
<img src="https://github.com/jwcse/DeepLearning/blob/master/img/cnn_overview2.PNG" width="800" height="250">



### Convolution

Assuming that there are two functions, one function is reversed and shifted. 

To that function, the other function is multiplied and then integrated.

These process is performed in unit of filter as filter is moved through the image.

(Let's think one function is image, and the other function is filter)

The picture below shows an example of convolution operation on 2-dimension data.

<img src="https://github.com/jwcse/DeepLearning/blob/master/img/convolution_ex.PNG" width="600" height="500">




### Characteristics of CNN

* Locality(Local Connectivity)

    CNN utilizes local information as receptive field. Correlation on spatially adjacent signal is extracted using non-linear filter. By using various filters, local featrue can be extracted. After this, through *subsampling* process and iterative filter operation on local feature, global feature can be extracted.


* Shared Weights

    Number of variables needed can be decreased by using identical filter iteratively.

* Pre-processing is not needed


CNN is classifed as locally connected nerual net, and this kind of neural net produces smaller weights compared to fully connected neural net. 
And this enables flexible handling of input image data.

### Layers - Convolutional, Pooling, Feedforward

#### Convolutional Layer - creation of feature map

Within the size of patch, same size of filter(kernel) which contains weights are computed to input image. The computation is done by 
dot product. After computation, window is moved and computation is perfomed again. Each result of computation value is put into element of feature map. 

The window is moved by size of step, called 'stride'. For example, if stride is equal to two, filter is applied jumping two pixels. 

Also, 'padding' can be done to the original image, which means certain value can be added to boundary of the input value array.


The output size should be different based on stride and patch size. 

For example, let's assume that input image size is 32x32x1, filter size is 5x5x1, and stride is 1x1. 
Then, output array size would be 28x28.

In addition, depending on number of filters, output's depth would be different. Each filter's size is same but contains different values.

If we use 6 filters, for instance, the output's depth would be 6.

#### Pooling Layer - subsample

Purpose is to reduce information generated by convolutional layer.

One of the representative way is *max pooling*. With certain filter size and stride, maximum value in the area is put into the element of output.

Another representative way is *average pooling*, which computes average value in window.

<img src="https://github.com/jwcse/DeepLearning/blob/master/img/subsampling.PNG" width="500" height="500">



#### Feedforward layer - classification ; fully connected layer

This utilizes features produced by convolution layer and pooling layer to classify.


### Snippet Code in Pytorch

```python
    # convolution layer
    torch.nn.Conv2d(in_channels, out_channels, kernel_size)
    
    # poolying layer
    nn.MaxPool2d(kernel_size)
    
    # Feedforward layer
    nn.Linear(320, 10)  # and then return with softmax(for example)  
```

### Inception module 
We can use various filters in convolution. The concept of inception is to try possible filters and concatenate all as output.

But before processing with each filter, 1x1 convolution is performed and then processed by each filter.

By doing so, we can reduce quantity of computation singnificantly.
 


### Problems with stacking layers

- Vanishing gradients problem
    
- Back propagation kind of gives up...
    
- Degradation problem ; with increased network depth accuracy gets saturated  and then rapidly degrades


Solution : *Deep Residual Learning*(ResNEt) ; by passing connection -> help propagate gradient gradients 



