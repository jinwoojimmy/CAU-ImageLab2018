# 28/05/18 Daily Report


## CNN Architecture

*CNN(Convolutional Neural Network)* is neural network utilized in image processing , MLP and so on.
The key idea is *convolution*, which means only small portion of image is handled at a time. This small portion is called 'patch',
and whole input image is processed by size of the patch.

The picture below shows CNN architecture.
    
### Process of CNN

<img src="https://github.com/jwcse/DeepLearning/blob/master/img/cnn_overview.PNG" width="800" height="250">


### Overview of CNN
    
<img src="https://github.com/jwcse/DeepLearning/blob/master/img/cnn_overview2.PNG" width="800" height="250">





CNN is classifed as locally connected nerual net, and this kind of neural net produces smaller weights compared to fully connected neural net. 
And this enables flexible handling of input image data.



1. Convolutional Layer - creation of feature map

Within the size of patch, same size of filter(kernel) which contains weights are computed to input image. The computation is done by 
dot product. After computation, window is moved and computation is perfomed again. Each result of computation value is put into element of
feature map. The window is moved by step, called 'stride'. Also, 'padding' can be done to the original image, which means zero values can be added
to boundary of the input value array.
The output size should be different based on stride and patch size. For example, let's assume that input image size is 32x32x1,
filter size is 5x5x1, and stride is 1x1. Then, output array size would be 28x28.

In addition, depending on number of filters, output's depth would be different. Each filter's size is same but contains different values.
If we use 6 filters, for instance, the output's depth would be 6.

2. Pooling Layer - subsample

Purpose is to reduce information generated by convolutional layer.
One of the representative way is *max pooling*. With certain filter size and stride, maximum value in the area is put into the element of output.

3. Feedforward layer - classification ; fully connected layer

This utilizes features produced by convolution layer and pooling layer to classify.


### Snippet Code in Pytorch

```python
    # convolution layer
    torch.nn.Conv2d(in_channels, out_channels, kernel_size)
    
    # poolying layer
    nn.MaxPool2d(kernel_size)
    
    # Feedforward layer
    nn.Linear(320, 10)  # and then return with softmax(for example)  
```

### Inception module 
We can use various filters in convolution. The concept of inception is to try possible filters and concatenate all as output.

But before processing with each filter, 1x1 convolution is performed and then processed by each filter.

By doing so, we can reduce quantity of computation singnificantly.
 


### Problems with stacking layers

- Vanishing gradients problem
    
- Back propagation kind of gives up...
    
- Degradation problem ; with increased network depth accuracy gets saturated  and then rapidly degrades


Solution : *Deep Residual Learning*(ResNEt) ; by passing connection -> help propagate gradient gradients 



