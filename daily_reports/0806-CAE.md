# 06/08/18 Daily Report

## Convolutional Autoencoder(CAE)

### Intro

The concept of Convolutional Autoencoder was first published on 2011 by Jonathan Masci from Swiss, with name of 
[Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction](http://pdfs.semanticscholar.org/1c6d/990c80e60aa0b0059415444cdf94b3574f0f.pdf)

After that good papers are being published. 

Here is one interesting paper, [DeepPainter: Painter Classification Using Deep Convolutional Autoencoders](http://elidavid.com/pubs/deeppainter.pdf) which was published at 2016.



Usually, a painter's artifact is not that much and it is difficult to utilize *data augmentation* to increase training data. 

Therefore, training with small quantity of training data in supervised learning way can lead to overfitting problem.

So we can consider unsupervised learning like using Autoencoder.



### DeepPainter

The DeepPainter trains with unsupervised learning. In order to do so, fully connected layer is seperated and convolutional layer and pooling layer part is trained with Autoencoder-way.

After training, fully connected layer part is fine-tuned in supervised learning-way.

So, front part is form of Stacked Convolutional Autoencoder and Decoder part should be added in order to train.


<img src="https://github.com/jwcse/DeepLearning/blob/master/img/CAE_overview.PNG" width="750" height="200">

In DeepPainter, max-pooling is used but this can be problem when constitute decode network, because the extracted maximum value in the pooling window can't be placed in appropriate position when size is shrinked.

So, in DeepPainter, pooling position is saved, so that we can figure out appropriate position when unpooling.

The picture below shows the way.

<img src="https://github.com/jwcse/DeepLearning/blob/master/img/CAE_unpooling.PNG" width="500" height="400">



After this process, training is proceeded as traditional training way of Autoencoder, which means that specific labeling is not needed because it is proceeded in unsupervised learning-way.

In unsupervised learning, training data was noised as case of Denoising Autoencoder.

After finish of training, decoder is eliminated and fully connected layer for classification is connected.


Now, classifier part is trained. Because front part is already trained, this can be categorized as fine-tuning.




#### Performance Result of DeepPainter

<img src="https://github.com/jwcse/DeepLearning/blob/master/img/CAE_performance.PNG" width="600" height="500">


### Example Code

Referenced from [GunhoChoi's code](https://github.com/GunhoChoi/PyTorch-FastCampus/blob/master/08_Autoencoder/1_Convolutional_Autoencoder.ipynb)

```python

"""
    Referenced from 
            https://github.com/GunhoChoi/PyTorch-FastCampus/blob/master/08_Autoencoder/1_Convolutional_Autoencoder.ipynb
   
    Convolutional Autoencoder
        - MNIST dataset
        - Convolutional Neural Network
        - 2 hidden-layers
"""


## Settings
# Import required libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
import matplotlib.pyplot as plt

# Set hyper-parameters
batch_size  = 100
learning_rate = 0.0002
num_epoch = 1


## Data
# Download Data
mnist_train = dset.MNIST("./", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)
mnist_test = dset.MNIST("./", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)

# Set DataLoader
train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)
test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)


## Model & Optimizer
# Model
class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1),  # batch x 16 x 28 x 28
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.Conv2d(16, 32, 3, padding=1),  # batch x 32 x 28 x 28
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 64, 3, padding=1),  # batch x 32 x 28 x 28
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(2, 2)  # batch x 64 x 14 x 14
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),  # batch x 64 x 14 x 14
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, padding=1),  # batch x 64 x 7 x 7
            nn.ReLU()
        )

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.view(batch_size, -1)
        return out


encoder = Encoder().cuda()


class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.layer1 = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1),
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.ConvTranspose2d(128, 64, 3, 1, 1),
            nn.ReLU(),
            nn.BatchNorm2d(64)
        )
        self.layer2 = nn.Sequential(
            nn.ConvTranspose2d(64, 16, 3, 1, 1),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.ConvTranspose2d(16, 1, 3, 2, 1, 1),
            nn.ReLU()
        )

    def forward(self, x):
        out = x.view(batch_size, 256, 7, 7)
        out = self.layer1(out)
        out = self.layer2(out)
        return out


decoder = Decoder().cuda()


# Loss func & Optimizer
parameters = list(encoder.parameters())+ list(decoder.parameters())
loss_func = nn.MSELoss()
optimizer = optim.Adam(parameters, lr=learning_rate)



## Train

try:
    encoder, decoder = torch.load('./model/conv_autoencoder.pkl')
    print("\n--------model restored--------\n")
except:
    print("\n--------model not restored--------\n")
    pass

for i in range(num_epoch):
    for j, [image, label] in enumerate(train_loader):
        optimizer.zero_grad()

        image = Variable(image).cuda()
        output = encoder(image)
        output = decoder(output)
        loss = loss_func(output, image)

        loss.backward()
        optimizer.step()

    if j % 10 == 0:
        torch.save([encoder, decoder], './model/conv_autoencoder.pkl')
        print(loss)


## Check with Train image
out_img = torch.squeeze(output.cpu().data)
print(out_img.size())

for i in range(5):
    #plt.imshow(torch.squeeze(image[i]).numpy(),cmap='gray')
    #plt.show()
    plt.imshow(out_img[i].numpy(),cmap='gray')
    plt.show()




```


